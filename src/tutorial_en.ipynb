{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "This is the tutorial for \"Tadano Crane Slewing Operation Optimization Challenge\".   \n",
    "In this tutorial, we will see how the simulator works, how to design and implement the control algorithm, and the evaluation of the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Pre-analysis\n",
    "1. Algorithm for Controlling the Crane Simulator\n",
    "1. Controlling the Crane Simulator\n",
    "1. Making the File for Submission\n",
    "1. For Further Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-analysis\n",
    "We will see how the crane simulator works by inputing some sequence of lever values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Sequences\n",
    "Notice that the lever value is \"float\" and ranges from 0.0 to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_1 = []\n",
    "for i in range(1001):\n",
    "    if i <= 100:\n",
    "        sequence_1.append(0.01*i)\n",
    "    elif i > 100 and i <= 200:\n",
    "        sequence_1.append(2-0.01*i)\n",
    "    else:\n",
    "        sequence_1.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_2 = []\n",
    "for i in range(1001):\n",
    "    if i <= 500:\n",
    "        sequence_2.append(0.002*i)\n",
    "    elif i > 500 and i <= 1000:\n",
    "        sequence_2.append(2-0.002*i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_3 = []\n",
    "for i in range(1001):\n",
    "    if i <= 500:\n",
    "        sequence_3.append(0.5)\n",
    "    else:\n",
    "        sequence_3.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_4 = []\n",
    "for i in range(1001):\n",
    "    sequence_4.append(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Sequences\n",
    "We will visualize the sequences with time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(1001)*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2,sharex=True, sharey=True, figsize=(15,10))\n",
    "axes[0,0].plot(t, sequence_1)\n",
    "axes[0,0].set_title('sequence_1', fontsize=20)\n",
    "axes[0,0].set_xlabel('time[s]', fontsize=15)\n",
    "axes[1,0].plot(t, sequence_2)\n",
    "axes[1,0].set_title('sequence_2', fontsize=20)\n",
    "axes[1,0].set_xlabel('time[s]', fontsize=15)\n",
    "axes[0,1].plot(t, sequence_3)\n",
    "axes[0,1].set_title('sequence_3', fontsize=20)\n",
    "axes[0,1].set_xlabel('time[s]', fontsize=15)\n",
    "axes[1,1].plot(t, sequence_4)\n",
    "axes[1,1].set_title('sequence_4', fontsize=20)\n",
    "axes[1,1].set_xlabel('time[s]', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputing the Sequences to the Crane Simulator\n",
    "We will input the sequences to the crane simulator and see the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will read the configurations for the simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# read the parameters\n",
    "config_dir = './configs'\n",
    "with open(os.path.join(config_dir, 'env_params.json')) as f:\n",
    "    env_params = json.load(f)\n",
    "with open(os.path.join(config_dir, 'sim_params.json')) as f:\n",
    "    sim_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in sim_params.items():\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(sequence, crane_env):\n",
    "    # control result\n",
    "    result = {}\n",
    "    result['senkai_radian'] = []\n",
    "    result['circular_displacement'] = []\n",
    "    result['radial_displacement'] = []\n",
    "\n",
    "    # get the initial observation\n",
    "    observation = crane_env.reset()\n",
    "\n",
    "    # start the simulator\n",
    "    crane_env.start()\n",
    "    done = False\n",
    "    t = 0\n",
    "    while not done:\n",
    "        # step foward\n",
    "        observation, reward, done, info = crane_env.step(sequence[t])\n",
    "        result['senkai_radian'].append(np.deg2rad(observation['turning_encoder_angle_deg']))\n",
    "        result['circular_displacement'].append(observation['hook_diff_c_m'])\n",
    "        result['radial_displacement'].append(observation['hook_diff_r_m'])\n",
    "        \n",
    "        t += 1\n",
    "\n",
    "        if t == len(sequence):\n",
    "            done = True\n",
    "\n",
    "    # stop the simulator\n",
    "    crane_env.stop()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will instanciate the simulator at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import env_user\n",
    "\n",
    "crane_env = env_user.CraneEnv(env_params, sim_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run the simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = play(sequence_1, crane_env)\n",
    "result_2 = play(sequence_2, crane_env)\n",
    "result_3 = play(sequence_3, crane_env)\n",
    "result_4 = play(sequence_4, crane_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Outputs\n",
    "We will visualize the outputs with time.  \n",
    "Since the angular velocity[rad/s] is not observable, we will compute it from 'senkai_radian'('turning_encoder_angle_deg')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(result, sequence):\n",
    "    # computing the angular velocity\n",
    "    senkai_velocity = []\n",
    "    for i in range(len(result['senkai_radian'])):\n",
    "        if i == 0:\n",
    "            senkai_velocity.append(0)\n",
    "        else:\n",
    "            senkai_velocity.append((result['senkai_radian'][i]-result['senkai_radian'][i-1])/0.01)\n",
    "    result['senkai_velocity'] = senkai_velocity\n",
    "\n",
    "    # Plotting the result\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(np.arange(len(result['circular_displacement']))*0.01, result['circular_displacement'], label='circular displacement [m]')\n",
    "    plt.plot(np.arange(len(result['radial_displacement']))*0.01, result['radial_displacement'], label='radial displacement [m]')\n",
    "    plt.plot(np.arange(len(result['senkai_radian']))*0.01, result['senkai_radian'], label=\"senkai angle [rad]\")\n",
    "    plt.plot(np.arange(len(result['senkai_velocity']))*0.01, result['senkai_velocity'], label=\"senkai velocity [rad/s]\")\n",
    "    plt.plot(np.arange(len(sequence))*0.01, sequence, label=\"lever sequence [-1 ~ 1]\")\n",
    "\n",
    "    plt.xlabel('Time [s]', fontsize=15)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(result_1, sequence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(result_2, sequence_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(result_3, sequence_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(result_4, sequence_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the circular displacement(load swing of the circumference direction) and the radial displacement(load swing of the radial direction) are relatively sensitive to the lever value so we have to increase it gradually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithm for Controlling the Crane Simulator\n",
    "From the pre-analysis above, we will design and implement simple rule-based control algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Agent\n",
    "We will implement the agent to control the crane simulator.  \n",
    "The agent must have at least the following methods:  \n",
    "- `get_model`\n",
    "- `set_params`\n",
    "- `policy`\n",
    "\n",
    "`get_model` instanciates the agent and loads some model if used. `set_params` sets parameters such as 'senkai_target_angle', 'weight_t', 'wire_ratio', etc. `policy` returns the next lever value after the observations are passed. The next lever value should range from 0 to 1.\n",
    "\n",
    "The parameters for `set_params` are as follows.\n",
    "\n",
    "|  name  |  type  |  unit  |  range  |  default  |  description  |\n",
    "| ---- | :----: | :----: | :----: | :----: | ---- |\n",
    "|  senkai_target_angle  |  float  |  deg  |  0 ~ 180  |  -  |  Target angle from the starting point  |\n",
    "|  weight_t  |  float  |  t  |  0 ~ 4  |  1  |  Weight of the hanging load  |\n",
    "|  wire_ratio  |  float  |  -  |  0.1 ~ 0.9  |  0.8  |  The length of the wire  |\n",
    "|  init_kifuku_deg  |  float  |  deg  |  10 ~ 80  |  60  |  Initial value of the ups and downs angle  |\n",
    "|  init_yure_senkai_m  |  float  |  m  |  -1 ~ 1  |  0  |  Load swing initial value of the radial direction  |\n",
    "|  init_yure_kifuku_m  |  float  |  m  |  -1 ~ 1  |  0  |  Load swing initial value of the circumference direction  |\n",
    "|  param_randomize_seed  |  uint  |  -  |  -  |  0  |  Randomize seed of the internal parameter(== 0 : seed is not fixed)  |\n",
    "\n",
    "The observations passed to `policy` are as follows.\n",
    "\n",
    "|  name  |  type  |  unit  |  description  |\n",
    "| ---- | :----: | :----: | ---- |\n",
    "|  step  |  uint  |  -  |  The practice step count of simulation  |\n",
    "|  turning_lever_value  |  float  |  -  |  Turning lever operation quantity  |\n",
    "|  turning_encoder_angle_deg  |  float  |  deg  |  Turning encoder angle  |\n",
    "|  turning_encoder_acquisition_time  |  float  |  ms  |  The turning encoder acquisition time  |\n",
    "|  working_radius_m  |  float  |  m  |  Work radius  |\n",
    "|  actual_load_t  |  float  |  t  |  Weight of the actual load  |\n",
    "|  main_wire_length_m  |  float  |  m  |  The length of the wire  |\n",
    "|  boom_top_x_m  |  float  |  m  |  x coordinate of the boom top  |\n",
    "|  boom_top_y_m  |  float  |  m  |  y coordinate of the boom top  |\n",
    "|  boom_top_z_m  |  float  |  m  |  z coordinate of the boom top  |\n",
    "|  boom_top_status  |  uint  |  -  |  When values are updated = 1, not updated = 0. The value is updated at 10Hz.  |\n",
    "|  left_turning_pressure_mpa  |  float  |  MPa  |  Pressure of the left turning  |\n",
    "|  right_turning_pressure_mpa  |  float  |  MPa  |  Pressure of the right turning  |\n",
    "|  tawami_diff_deg  |  float  |  deg  |  Flection of the circumference direction  |\n",
    "|  hook_x_m  |  float  |  m  |  x coordinate of the hook  |\n",
    "|  hook_y_m  |  float  |  m  |  y coordinate of the hook  |\n",
    "|  hook_z_m  |  float  |  m  |  z coordinate of the hook  |\n",
    "|  hook_status  |  uint  |  -  |  When values are updated = 1, not updated = 0. The value is updated at 10Hz.  |\n",
    "|  hook_diff_c_m  |  float  |  m  |  Load swing of the circumference direction  |\n",
    "|  hook_diff_r_m  |  float  |  m  |  Load swing of the radial direction  |\n",
    "\n",
    "When the simulation runs, the simulator is instanciated at first. Then `get_model` is called to instanciate the agent, and `set_params` is called to set the parameters from the passed parameters. In each step, observations are generated from the simulator and passed to `policy` and the next lever value is returned, then passed to the simulator, and so on, until `done` flag will be `True`(while `done` flag is `False`). `done` flag will be `True` if the lever value remains 0 for 1000 steps, or the total steps is greater than or equal to 100000.\n",
    "\n",
    "```\n",
    "# instanciate the simulator\n",
    "crane_env = env_user.CraneEnv(env_params, sim_params)\n",
    "\n",
    "# instanciate the agent\n",
    "crane_agent = agent.Agent.get_model('./model')\n",
    "crane_agent.set_params(external_params)\n",
    "\n",
    "# get the initial observation\n",
    "observation = env.reset()\n",
    "\n",
    "# run the simulation\n",
    "done = False\n",
    "while not done:\n",
    "    # next lever value\n",
    "    action = crane_agent.policy(observation)\n",
    "\n",
    "    # step foward\n",
    "    observation, reward, done, info = crane_env.step(action)\n",
    "```\n",
    "To implement simple rule-based algorithm, we will define some model parameters in `get_model`.  \n",
    "The model parameters are as follows:\n",
    "- max_steps\n",
    "- max_velocity\n",
    "- del_lever\n",
    "- max_angle\n",
    "\n",
    "Check `policy` below to see how it works.    \n",
    "Since the angular velocity[rad/s] is not observable, we will compute it from 'turning_encoder_angle_deg' which is available observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, action_range):\n",
    "        self.model = None\n",
    "        self.action_range = action_range\n",
    "        self.step = 0\n",
    "        self.observations = self.init_log()\n",
    "\n",
    "    @classmethod\n",
    "    def get_model(cls, model_path):\n",
    "        action_range = (0.0, 1.0)\n",
    "        agent = cls(action_range)\n",
    "\n",
    "        # load some model\n",
    "        if os.path.exists(model_path):\n",
    "            with open(model_path) as f:\n",
    "                agent.model = json.load(f)\n",
    "        else:\n",
    "            agent.model = {'max_steps': 5000,\n",
    "                           'max_velocity': 0.3,\n",
    "                           'del_lever': 0.01,\n",
    "                           'max_angle': 0.8}\n",
    "\n",
    "        return agent\n",
    "\n",
    "    def set_params(self, params):\n",
    "        \"\"\"\n",
    "        args:\n",
    "          params (data type: dict)\n",
    "            - 'senkai_target_angle'\n",
    "            - 'weight_t'\n",
    "            - 'wire_ratio'\n",
    "            - 'init_kifuku_deg'\n",
    "            - 'init_yure_senkai_m'\n",
    "            - 'init_yure_kifuku_m'\n",
    "            - 'param_randomize_seed'\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "\n",
    "    def policy(self, observation):\n",
    "        \"\"\"\n",
    "        args:\n",
    "          observation (data type: dict):\n",
    "            - 'step'\n",
    "            - 'turning_lever_value'\n",
    "            - 'turning_encoder_angle_deg'\n",
    "            - 'turning_encoder_acquisition_time'\n",
    "            - 'working_radius_m'\n",
    "            - 'actual_load_t'\n",
    "            - 'main_wire_length_m'\n",
    "            - 'boom_top_x_m'\n",
    "            - 'boom_top_y_m'\n",
    "            - 'boom_top_z_m'\n",
    "            - 'boom_top_status'\n",
    "            - 'left_turning_pressure_mpa'\n",
    "            - 'right_turning_pressure_mpa'\n",
    "            - 'tawami_diff_deg'\n",
    "            - 'hook_x_m'\n",
    "            - 'hook_y_m'\n",
    "            - 'hook_z_m'\n",
    "            - 'hook_status'\n",
    "            - 'hook_diff_c_m'\n",
    "            - 'hook_diff_r_m'\n",
    "        available observation\n",
    "\n",
    "        returns:\n",
    "          next_lever_value(data type: float, 0 <= and <= 1)\n",
    "        \"\"\"\n",
    "        # save the observations\n",
    "        if self.step > observation['step']:\n",
    "            self.observations = self.init_log()\n",
    "            self.step = 0\n",
    "        self.observations['senkai_radian'].append(np.deg2rad(observation['turning_encoder_angle_deg']))\n",
    "\n",
    "        # computing the angular velocity\n",
    "        velocity = 0.0\n",
    "        if len(self.observations['senkai_radian']) > 1:\n",
    "            velocity = (self.observations['senkai_radian'][-1]-self.observations['senkai_radian'][-2])/0.01\n",
    "        self.observations['senkai_velocity'].append(velocity)\n",
    "\n",
    "        # computing the next lever value\n",
    "        next_lever_value = 0.0\n",
    "        if self.step <= self.model['max_steps']:\n",
    "            if observation['turning_encoder_angle_deg'] < self.params['senkai_target_angle']*self.model['max_angle']:\n",
    "                if self.observations['senkai_velocity'][-1] <= self.model['max_velocity']:\n",
    "                    next_lever_value = observation['turning_lever_value'] + self.model['del_lever']\n",
    "                else:\n",
    "                    next_lever_value = observation['turning_lever_value'] - self.model['del_lever']\n",
    "\n",
    "            else:\n",
    "                if self.observations['senkai_velocity'][-1] <= 0.0:\n",
    "                    next_lever_value = observation['turning_lever_value'] + self.model['del_lever']\n",
    "                else:\n",
    "                    next_lever_value = observation['turning_lever_value'] - self.model['del_lever']\n",
    "\n",
    "        next_lever_value = min(max(next_lever_value, self.action_range[0]), self.action_range[1])\n",
    "\n",
    "        self.step += 1\n",
    "\n",
    "        return next_lever_value\n",
    "\n",
    "    def init_log(self):\n",
    "        observations = {}\n",
    "        observations['senkai_radian'] = []\n",
    "        observations['senkai_velocity'] = []\n",
    "\n",
    "        return observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the Model Parameters\n",
    "We will optimize the model parameters using bayesian optimization(https://github.com/fmfn/BayesianOptimization).  \n",
    "The parameters to be optimized are as follows:\n",
    "- max_steps\n",
    "- max_velocity\n",
    "- del_lever\n",
    "- max_angle\n",
    "\n",
    "The target will be the score defined in the competition(https://signate.jp/competitions/428#evaluation). It can be computed using some functions defined in \"evaluate.py\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bayes_opt import BayesianOptimization, UtilityFunction\n",
    "from evaluate import evaluation_crane\n",
    "\n",
    "class Optimizer(object):\n",
    "    def __init__(self, env, agent, evaluation_params, external_params):\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        self.evaluation_params = evaluation_params\n",
    "        self.external_params = external_params\n",
    "\n",
    "    def play(self):\n",
    "        # get the initial observation\n",
    "        observation = self.env.reset()\n",
    "\n",
    "        # start the simulator\n",
    "        self.env.start()\n",
    "        done = False\n",
    "        while not done:\n",
    "            # time the control\n",
    "            time_start = time.perf_counter()\n",
    "            action = self.agent.policy(observation)\n",
    "            runtime = time.perf_counter() - time_start\n",
    "            self.env.update_runtime_results(runtime)\n",
    "\n",
    "            # step foward\n",
    "            observation, reward, done, info = self.env.step(action)\n",
    "\n",
    "        # get the control results\n",
    "        result = self.env.get_control_results()\n",
    "\n",
    "        # stop the simulator\n",
    "        self.env.stop()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def compute_target(self, result):\n",
    "        flag, score = evaluation_crane(result, self.evaluation_params, self.external_params)\n",
    "        if flag:\n",
    "            print('Score: {}\\n'.format(score))\n",
    "            return score\n",
    "        else:\n",
    "            print('Score: {}\\n'.format(0.0))\n",
    "            return 0.0\n",
    "\n",
    "    def optimize(self, pbounds, n = 10):\n",
    "        # set the optimizer\n",
    "        opt = BayesianOptimization(f = None,\n",
    "                                   pbounds = pbounds,\n",
    "                                   verbose = 2,\n",
    "                                   random_state = 1)\n",
    "        opt.set_gp_params(normalize_y = False)\n",
    "        utility = UtilityFunction(kind=\"ucb\", kappa=2.5, xi=0.0)\n",
    "\n",
    "        # run the optimization\n",
    "        for i in range(n):\n",
    "            print('Optimization {}:\\n'.format(i+1))\n",
    "            # suggest the next parameters\n",
    "            next_point = opt.suggest(utility)\n",
    "\n",
    "            # set the suggested parameters\n",
    "            self.agent.model = next_point\n",
    "\n",
    "            # get the result\n",
    "            result = self.play()\n",
    "\n",
    "            # compute the score\n",
    "            score = self.compute_target(result)\n",
    "\n",
    "            # register the result for the given parmaeters\n",
    "            opt.register(params = next_point, target = score)\n",
    "\n",
    "        # set the best model parameters\n",
    "        self.agent.model = opt.max['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configurations of the simulator(environment) and the external parameters passed to the agent such as target angle('senkai_target_angle') are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_dir, 'env_params.json')) as f:\n",
    "    env_params = json.load(f)\n",
    "with open(os.path.join(config_dir, 'sim_params.json')) as f:\n",
    "    sim_params = json.load(f)\n",
    "with open(os.path.join(config_dir, 'external_params.json')) as f:\n",
    "    external_params = json.load(f)\n",
    "external_params.update(sim_params['state_init'])\n",
    "\n",
    "with open(os.path.join(config_dir, 'evaluation_params.json')) as f:\n",
    "    evaluation_params = json.load(f)\n",
    "\n",
    "print('configurations:')\n",
    "for k, v in sim_params.items():\n",
    "    print(' ', k)\n",
    "    print(' ', v)\n",
    "print('\\nexternal parameters:')\n",
    "for k, v in external_params.items():\n",
    "    print(' ', k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the model parameter bounds in `pbounds` object and the number of iterations in `n` object as follows.  \n",
    "Then we will run the optimization by `optimize` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciate the agent\n",
    "os.makedirs('model', exist_ok=True)\n",
    "model_path = os.path.join('model', 'params.json')\n",
    "action_range = (0.0, 1.0)\n",
    "agent = Agent(action_range)\n",
    "agent.set_params(external_params)\n",
    "\n",
    "# instanciate the optimizer(pass \"crane_env\" instanciated above which were set \"env_params\" and \"sim_params\".)\n",
    "optimizer = Optimizer(crane_env, agent, evaluation_params, external_params)\n",
    "pbounds = {'max_steps': (9000, 12000),\n",
    "           'max_velocity': (0.2, 0.4),\n",
    "           'del_lever': (0.0005, 0.001),\n",
    "           'max_angle': (0.4, 0.9)}\n",
    "\n",
    "# run the optimizer\n",
    "n = 100\n",
    "optimizer.optimize(pbounds, n)\n",
    "\n",
    "# save the best parameters\n",
    "with open(model_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(agent.model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Controlling the Crane Simulator\n",
    "We will control the crane simulator using the optimized model and evaluate the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Simulation\n",
    "We will run the simulation and save the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(crane_env, crane_agent, output_path):\n",
    "    # get the initial observation\n",
    "    observation = crane_env.reset()\n",
    "    \n",
    "    # start the simulator\n",
    "    crane_env.start()\n",
    "    done = False\n",
    "    while not done:\n",
    "        # time the control\n",
    "        time_start = time.perf_counter()\n",
    "        action = crane_agent.policy(observation)\n",
    "        runtime = time.perf_counter() - time_start\n",
    "        crane_env.update_runtime_results(runtime)\n",
    "        \n",
    "        # step foward\n",
    "        observation, reward, done, info = crane_env.step(action)\n",
    "\n",
    "    # save the control results\n",
    "    crane_env.save_control_results(output_path)\n",
    "\n",
    "    # stop the simulator\n",
    "    crane_env.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output will be saved in `output_path` defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crane_agent = Agent.get_model(model_path)\n",
    "crane_agent.set_params(external_params)\n",
    "output_path = os.path.join('output', 'control_results.json')\n",
    "run(crane_env, crane_agent, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Output\n",
    "We will evaluate the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configurations of the simulator(environment) and the external parameters passed to the agent such as target angle('senkai_target_angle') are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_dir, 'env_params.json')) as f:\n",
    "    env_params = json.load(f)\n",
    "with open(os.path.join(config_dir, 'sim_params.json')) as f:\n",
    "    sim_params = json.load(f)\n",
    "with open(os.path.join(config_dir, 'external_params.json')) as f:\n",
    "    external_params = json.load(f)\n",
    "external_params.update(sim_params['state_init'])\n",
    "print('configurations:')\n",
    "for k, v in sim_params.items():\n",
    "    print(' ', k)\n",
    "    print(' ', v)\n",
    "print('\\nexternal parameters:')\n",
    "for k, v in external_params.items():\n",
    "    print(' ', k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check the score in the given condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read parameters\n",
    "with open(os.path.join(config_dir, 'evaluation_params.json')) as f:\n",
    "    params = json.load(f)\n",
    "with open(os.path.join(config_dir, 'external_params.json')) as f:\n",
    "    external_params = json.load(f)\n",
    "print('Parameters for evaluation:')\n",
    "for k, v in params.items():\n",
    "    print(' ', k, v)\n",
    "for k, v in external_params.items():\n",
    "    print(' ', k, v)\n",
    "\n",
    "# read the control result\n",
    "with open('./output/control_results.json') as f:\n",
    "    result = json.load(f)\n",
    "print('\\nCategories for evaluation:')\n",
    "for k in result.keys():\n",
    "    print(' ', k)\n",
    "\n",
    "# evaluate the result\n",
    "print('\\nEvaluation results:')\n",
    "flag, score = evaluation_crane(result, params, external_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Making the File for Submission\n",
    "We will make the file for submission of this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit \"agent.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the file for submission, we have to create `Agent` class implemented above, in \"agent.py\" file at first(also refer to \"README.md\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Simulator with the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following command and make sure the implemented agent runs as expected(also refer to \"README.md\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following command and make sure the implemented agent performs as expected(also refer to \"README.md\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the Zip File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run the following command and you can make the file for submission which is a zip file(also refer to \"README.md\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash submit.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. For Further Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we implemented a simple rule-based algorithm and optimized its parameters.  \n",
    "As we only considered a limited condition, we have to design the algorithm to make it robust(add some parameters for example).\n",
    "\n",
    "Reinforcement learning algorithms may cope with this problem(or we can combine a rule-based algorithm and a reinforcement learning algorithm to make it better). To use the reinforcement learning algorithm, we have to define the reward which should be generated from the environment at each step. In this competition, the reward is not given explicitly. Designing the proper reward to achieve good accuracy score may be important when using reinforcement learning algorithms. We can implement it in `step` method in \"env_user.py\"(it always returns 0 by default).\n",
    "\n",
    "We look forward to great ideas.  \n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c49f0bd7bba8bb14ce2871a5702e8b7f6af847bc808d73fa8c7d7c5307af8c3a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
